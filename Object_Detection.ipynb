{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HiQdFfVFbxGP"
   },
   "outputs": [],
   "source": [
    "pip install tensorflow opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aJjfM9taGAcg"
   },
   "outputs": [],
   "source": [
    "#train_data_directory = 'https://drive.google.com/drive/folders/16cEKULnazJsSyPzIZCSo2I6xjcCr80FL?usp=drive_link'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "urFKzo4JR_-t"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g9nvFDI0SCER"
   },
   "outputs": [],
   "source": [
    "def extract_box_count(filename):\n",
    "    parts = filename.lower().split('_')\n",
    "    for part in parts:\n",
    "        if 'boxes' in part:\n",
    "            try:\n",
    "                return int(part)\n",
    "            except ValueError:\n",
    "                pass\n",
    "    return 0  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UsonpkVkSDsQ"
   },
   "outputs": [],
   "source": [
    "def create_counting_model(input_shape=(224, 224, 3)):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='linear')) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0S7I-NNvSFOV"
   },
   "outputs": [],
   "source": [
    "model = create_counting_model()\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qql310t4SH75"
   },
   "outputs": [],
   "source": [
    "train_data_directory = '/content/drive/MyDrive/M_P Dataset csv/Inventorypictures'\n",
    "#https://drive.google.com/drive/folders/16cEKULnazJsSyPzIZCSo2I6xjcCr80FL?usp=drive_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GnfiueoILupf"
   },
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for filename in os.listdir(train_data_directory):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\"):\n",
    "            image_path = os.path.join(train_data_directory, filename)\n",
    "\n",
    "            image = cv2.imread(image_path)\n",
    "            image = cv2.resize(image, (224, 224))\n",
    "            image = image / 255.0 \n",
    "\n",
    "            image = np.expand_dims(image, axis=0)\n",
    "            count = np.array([[extract_box_count(filename)]])  \n",
    "\n",
    "            model.train_on_batch(image, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xe5v_2Y8LumA"
   },
   "outputs": [],
   "source": [
    "model.save('/content/drive/MyDrive/M_P Dataset csv/trained_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SI11C5EnSxqc"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.load_model('/content/drive/MyDrive/M_P Dataset csv/trained_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nU0n3FRbS39K"
   },
   "outputs": [],
   "source": [
    "def count_boxes(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image, (224, 224))  \n",
    "    image = image / 255.0  \n",
    "    image = np.expand_dims(image, axis=0)  \n",
    "\n",
    "    prediction = model.predict(image)\n",
    "    count = int(np.round(prediction[0][0]))\n",
    "\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1700594093291,
     "user": {
      "displayName": "Meenu Patel",
      "userId": "04891448876475488039"
     },
     "user_tz": -330
    },
    "id": "22w2po92S6Cn",
    "outputId": "14c193f1-6222-42e3-ab8b-985ae92e23ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 44ms/step\n",
      "The predicted box count is: 0\n"
     ]
    }
   ],
   "source": [
    "image_path = '/content/drive/MyDrive/M_P Dataset csv/Inventorypictures/20231025_145833.jpg'\n",
    "box_count = count_boxes(image_path)\n",
    "print(f'The predicted box count is: {box_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1523,
     "status": "ok",
     "timestamp": 1700594099054,
     "user": {
      "displayName": "Meenu Patel",
      "userId": "04891448876475488039"
     },
     "user_tz": -330
    },
    "id": "t3bmvsVBS8CV",
    "outputId": "d8b20c2c-fdb3-43a8-b3d4-051ecb3713b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 49ms/step\n",
      "The predicted box count is: 0\n"
     ]
    }
   ],
   "source": [
    "image_path = '/content/drive/MyDrive/M_P Dataset csv/Inventorypictures/20231025_145833.jpg'\n",
    "box_count = count_boxes(image_path)\n",
    "print(f'The predicted box count is: {box_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1124,
     "status": "ok",
     "timestamp": 1700594244738,
     "user": {
      "displayName": "Meenu Patel",
      "userId": "04891448876475488039"
     },
     "user_tz": -330
    },
    "id": "ntYyYjM-UBN_",
    "outputId": "e507068d-7a3f-40e5-a814-586ebc25ada5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 75ms/step\n",
      "Raw prediction values: [0.00244552]\n",
      "The predicted box count is: 0\n"
     ]
    }
   ],
   "source": [
    "def count_boxes(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image, (224, 224)) \n",
    "    image = image / 255.0  \n",
    "    image = np.expand_dims(image, axis=0) \n",
    "\n",
    "    prediction = model.predict(image)\n",
    "\n",
    "    raw_prediction = prediction[0]\n",
    "    print(f'Raw prediction values: {raw_prediction}')\n",
    "\n",
    "    count = int(np.round(raw_prediction))\n",
    "\n",
    "    return count\n",
    "\n",
    "image_path = '/content/drive/MyDrive/M_P Dataset csv/Inventorypictures/IMG-20231103-WA0049.jpeg'\n",
    "box_count = count_boxes(image_path)\n",
    "print(f'The predicted box count is: {box_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fqcBlGmtXkrW"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format\n",
    "from object_detection import model_lib_v2\n",
    "\n",
    "pipeline_config_path = '/content/drive/MyDrive/M_P Dataset csv/pipeline.config'\n",
    "model_dir = ''\n",
    "\n",
    "configs = config_util.get_configs_from_pipeline_file(pipeline_config_path)\n",
    "model_config = configs['model']\n",
    "\n",
    "\n",
    "config_util.save_pipeline_config(configs, pipeline_config_path)\n",
    "\n",
    "print(\"Training started...\")\n",
    "model_lib_v2.train_loop(\n",
    "    pipeline_config_path=pipeline_config_path,\n",
    "    model_dir=model_dir,\n",
    "    train_steps=your_train_steps,  \n",
    "    use_tpu=False,  \n",
    "    checkpoint_every_n=your_checkpoint_frequency, \n",
    ")\n",
    "\n",
    "print(\"Training finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zyMNO49kdFLk"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "model = tf.saved_model.load('/content/drive/MyDrive/M_P Dataset csv/trained_model.h5')    \n",
    "\n",
    "def count_boxes_faster_rcnn(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image_np = np.expand_dims(np.asarray(image, dtype=np.uint8), 0)\n",
    "\n",
    "    input_tensor = tf.convert_to_tensor(image_np, dtype=tf.float32)\n",
    "\n",
    "    detections = model(input_tensor)\n",
    "\n",
    "    box_count = detections['num_detections'][0].numpy()\n",
    "\n",
    "    return int(box_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xf9KZRodWLdB"
   },
   "outputs": [],
   "source": [
    "image_path = 'path/to/your/image.jpg'\n",
    "box_count = count_boxes_faster_rcnn(image_path)\n",
    "print(f'The predicted box count is: {box_count}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOT8dMsGQc9kj7hv4Bw4d8p",
   "mount_file_id": "1tnjewVbfsFTUWqi6fs7cpnhqYYSwJ0w0",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
